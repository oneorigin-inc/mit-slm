@echo off
REM DCC Model API Production Startup Script
REM Handles complete setup and startup of the DCC Model API service
REM - Creates custom Ollama model from local Modelfile
REM - Starts Docker containers (Ollama + DCC-API)
REM - Verifies service health and availability

echo ğŸš€ Starting DCC Model API in Production Mode...

REM Check if Docker is running
docker info >nul 2>&1
if %errorlevel% neq 0 (
    echo âŒ Docker is not running. Please start Docker first.
    pause
    exit /b 1
)

REM Check if required files exist
if not exist "docker-compose.yml" (
    echo âŒ docker-compose.yml not found. Please run from project root.
    pause
    exit /b 1
)

if not exist "config\ModelFile1.txt" (
    echo âŒ ModelFile1.txt not found in config directory.
    pause
    exit /b 1
)

if not exist "model\MIT_OB_Phi-4-mini-instruct.Q4_K_M.gguf" (
    echo âŒ Model file not found in model directory.
    pause
    exit /b 1
)

REM Create logs directory if it doesn't exist
if not exist "logs" mkdir logs

REM Clean up any existing containers
echo ğŸ§¹ Cleaning up existing containers...
docker-compose down

REM Build and start services
echo ğŸ”¨ Building and starting services...
docker-compose up --build -d

REM Wait for services to be healthy
echo â³ Waiting for services to be healthy...
timeout /t 10 /nobreak

REM Check Ollama health
echo ğŸ” Checking Ollama health...
for /L %%i in (1,1,30) do (
    powershell -Command "try { Invoke-WebRequest -Uri http://localhost:8000/api/tags -UseBasicParsing | Out-Null; exit 0 } catch { exit 1 }" >nul 2>&1
    if !errorlevel! equ 0 (
        echo âœ… Ollama is healthy
        goto :ollama_ready
    ) else (
        echo â³ Waiting for Ollama... (%%i/30)
        timeout /t 2 /nobreak
    )
)
echo âŒ Ollama failed to start properly
docker-compose logs ollama
pause
exit /b 1

:ollama_ready
REM Create the model
echo ğŸ“¥ Creating custom model from Modelfile...
docker exec ollama-server ollama create phi4badges -f /config/ModelFile1.txt

REM Verify model creation
echo ğŸ” Verifying model creation...
docker exec ollama-server ollama list

REM Check API health
echo ğŸ” Checking API health...
for /L %%i in (1,1,30) do (
    powershell -Command "try { Invoke-WebRequest -Uri http://localhost:8001/api/v1/health -UseBasicParsing | Out-Null; exit 0 } catch { exit 1 }" >nul 2>&1
    if !errorlevel! equ 0 (
        echo âœ… API is healthy
        goto :api_ready
    ) else (
        echo â³ Waiting for API... (%%i/30)
        timeout /t 2 /nobreak
    )
)
echo âŒ API failed to start properly
docker-compose logs api
pause
exit /b 1

:api_ready
echo ğŸ‰ DCC Model API is running in production mode!
echo ğŸ“Š API Health: http://localhost:8001/api/v1/health
echo ğŸ“š API Docs: http://localhost:8001/docs
echo ğŸ”§ Ollama: http://localhost:8000
echo ğŸ“ Logs: tail -f logs/api.log
echo.
echo ğŸ“‹ Model Information:
echo    - Model: phi4badges (created from ModelFile1.txt)
echo    - Model File: MIT_OB_Phi-4-mini-instruct.Q4_K_M.gguf
echo    - Ollama Port: 8000
echo    - API Port: 8001

pause
